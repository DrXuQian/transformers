"""
Qwen3-VL (Denseç‰ˆæœ¬) QKVå’ŒOutput ProjectionçŸ©é˜µå¤§å°åˆ†æ
åŸºäºä»£ç å’Œé…ç½®æ–‡ä»¶
"""

def analyze_qwen3_vl_matrix_sizes():
    """
    åˆ†æQwen3-VLçš„QKVå’ŒOutput projectionçŸ©é˜µå¤§å°
    """

    print("=" * 80)
    print("Qwen3-VL QKVå’ŒOutput ProjectionçŸ©é˜µå¤§å°")
    print("=" * 80)

    # é…ç½®å‚æ•°ï¼ˆåŸºäºQwen3-VL-7B-Instructï¼‰
    vision_config = {
        'hidden_size': 1024,
        'num_heads': 16,
        'head_dim': 64,  # hidden_size // num_heads
    }

    text_config = {
        'hidden_size': 2560,
        'num_attention_heads': 32,
        'num_key_value_heads': 8,  # GQA
        'head_dim': 80,  # hidden_size // num_attention_heads
    }

    print("\nğŸ“Š 1. Vision Encoderçš„æ³¨æ„åŠ›çŸ©é˜µ")
    print("-" * 40)
    print(f"é…ç½®ï¼š")
    print(f"â€¢ hidden_size = {vision_config['hidden_size']}")
    print(f"â€¢ num_heads = {vision_config['num_heads']}")
    print(f"â€¢ head_dim = {vision_config['head_dim']}")

    print(f"\nçŸ©é˜µå¤§å°ï¼š")

    # Visionä½¿ç”¨åˆå¹¶çš„QKV
    print(f"\nåˆå¹¶çš„QKVçŸ©é˜µ (self.qkv):")
    qkv_in = vision_config['hidden_size']
    qkv_out = vision_config['hidden_size'] * 3
    print(f"â€¢ nn.Linear({qkv_in}, {qkv_out}, bias=True)")
    print(f"â€¢ å‚æ•°é‡: {qkv_in * qkv_out} + {qkv_out} (bias) = {qkv_in * qkv_out + qkv_out:,}")

    print(f"\nåˆ†è§£åï¼š")
    print(f"â€¢ Q: [{qkv_in}, {vision_config['hidden_size']}]")
    print(f"â€¢ K: [{qkv_in}, {vision_config['hidden_size']}]")
    print(f"â€¢ V: [{qkv_in}, {vision_config['hidden_size']}]")

    print(f"\nOutput Projection (self.proj):")
    o_in = vision_config['hidden_size']
    o_out = vision_config['hidden_size']
    print(f"â€¢ nn.Linear({o_in}, {o_out}, bias=False)")
    print(f"â€¢ å‚æ•°é‡: {o_in * o_out:,}")

    print(f"\næ¯ä¸ªVision Blockçš„æ³¨æ„åŠ›å‚æ•°æ€»é‡ï¼š")
    vision_attn_params = qkv_in * qkv_out + qkv_out + o_in * o_out
    print(f"â€¢ {vision_attn_params:,} å‚æ•°")
    print(f"â€¢ 24å±‚æ€»è®¡: {vision_attn_params * 24:,} å‚æ•°")

    print("\n" + "=" * 80)
    print("ğŸ“Š 2. LLM Decoderçš„æ³¨æ„åŠ›çŸ©é˜µ")
    print("-" * 40)
    print(f"é…ç½®ï¼š")
    print(f"â€¢ hidden_size = {text_config['hidden_size']}")
    print(f"â€¢ num_attention_heads = {text_config['num_attention_heads']}")
    print(f"â€¢ num_key_value_heads = {text_config['num_key_value_heads']} (GQA 4:1)")
    print(f"â€¢ head_dim = {text_config['head_dim']}")

    print(f"\nçŸ©é˜µå¤§å°ï¼š")

    # LLMä½¿ç”¨åˆ†ç¦»çš„Qã€Kã€V
    print(f"\nQ Projection (self.q_proj):")
    q_in = text_config['hidden_size']
    q_out = text_config['num_attention_heads'] * text_config['head_dim']
    print(f"â€¢ nn.Linear({q_in}, {q_out}, bias=False)")
    print(f"â€¢ çŸ©é˜µå½¢çŠ¶: [{q_in}, {q_out}]")
    print(f"â€¢ å‚æ•°é‡: {q_in * q_out:,}")

    print(f"\nK Projection (self.k_proj):")
    k_in = text_config['hidden_size']
    k_out = text_config['num_key_value_heads'] * text_config['head_dim']
    print(f"â€¢ nn.Linear({k_in}, {k_out}, bias=False)")
    print(f"â€¢ çŸ©é˜µå½¢çŠ¶: [{k_in}, {k_out}]")
    print(f"â€¢ å‚æ•°é‡: {k_in * k_out:,}")

    print(f"\nV Projection (self.v_proj):")
    v_in = text_config['hidden_size']
    v_out = text_config['num_key_value_heads'] * text_config['head_dim']
    print(f"â€¢ nn.Linear({v_in}, {v_out}, bias=False)")
    print(f"â€¢ çŸ©é˜µå½¢çŠ¶: [{v_in}, {v_out}]")
    print(f"â€¢ å‚æ•°é‡: {v_in * v_out:,}")

    print(f"\nOutput Projection (self.o_proj):")
    o_in = text_config['num_attention_heads'] * text_config['head_dim']
    o_out = text_config['hidden_size']
    print(f"â€¢ nn.Linear({o_in}, {o_out}, bias=False)")
    print(f"â€¢ çŸ©é˜µå½¢çŠ¶: [{o_in}, {o_out}]")
    print(f"â€¢ å‚æ•°é‡: {o_in * o_out:,}")

    print(f"\næ¯ä¸ªDecoder Blockçš„æ³¨æ„åŠ›å‚æ•°æ€»é‡ï¼š")
    text_attn_params = q_in * q_out + k_in * k_out + v_in * v_out + o_in * o_out
    print(f"â€¢ {text_attn_params:,} å‚æ•°")
    print(f"â€¢ 36å±‚æ€»è®¡: {text_attn_params * 36:,} å‚æ•°")

    print("\n" + "=" * 80)
    print("ğŸ“Š 3. å¯¹æ¯”æ€»ç»“")
    print("-" * 40)

    print("\nVision Encoder (æ¯å±‚):")
    print(f"â€¢ QKV: 1024 â†’ 3072 (åˆå¹¶)")
    print(f"â€¢ O:   1024 â†’ 1024")
    print(f"â€¢ æ€»å‚æ•°: {vision_attn_params:,}")

    print("\nLLM Decoder (æ¯å±‚):")
    print(f"â€¢ Q: 2560 â†’ 2560")
    print(f"â€¢ K: 2560 â†’ 640 (GQA)")
    print(f"â€¢ V: 2560 â†’ 640 (GQA)")
    print(f"â€¢ O: 2560 â†’ 2560")
    print(f"â€¢ æ€»å‚æ•°: {text_attn_params:,}")

    print("\nå…³é”®å·®å¼‚:")
    print("1. Visionä½¿ç”¨åˆå¹¶çš„QKVçŸ©é˜µï¼ŒLLMä½¿ç”¨åˆ†ç¦»çš„Qã€Kã€V")
    print("2. Visionæ²¡æœ‰GQAï¼ŒLLMä½¿ç”¨4:1 GQA")
    print("3. Visionæœ‰biasï¼ŒLLMæ²¡æœ‰bias")
    print("4. LLMçš„æ³¨æ„åŠ›å‚æ•°é‡æ›´å¤§ï¼ˆçº¦2.8å€ï¼‰")

    print("\n" + "=" * 80)
    print("ğŸ“ 4. å®é™…è®¡ç®—ç¤ºä¾‹")
    print("-" * 40)

    print("\nå‡è®¾è¾“å…¥åºåˆ—é•¿åº¦ä¸º1000:")

    print("\nVision Encoder:")
    print("â€¢ è¾“å…¥: [1000, 1024]")
    print("â€¢ QKVè¾“å‡º: [1000, 3072]")
    print("â€¢ æ‹†åˆ†å: Q[1000, 1024], K[1000, 1024], V[1000, 1024]")
    print("â€¢ é‡å¡‘ä¸ºå¤šå¤´: Q[1000, 16, 64], K[1000, 16, 64], V[1000, 16, 64]")
    print("â€¢ æ³¨æ„åŠ›è¾“å‡º: [1000, 1024]")
    print("â€¢ ç»è¿‡O_proj: [1000, 1024]")

    print("\nLLM Decoder:")
    print("â€¢ è¾“å…¥: [1000, 2560]")
    print("â€¢ Qè¾“å‡º: [1000, 2560]")
    print("â€¢ Kè¾“å‡º: [1000, 640]")
    print("â€¢ Vè¾“å‡º: [1000, 640]")
    print("â€¢ é‡å¡‘ä¸ºå¤šå¤´: Q[1000, 32, 80], K[1000, 8, 80], V[1000, 8, 80]")
    print("â€¢ K/Vé€šè¿‡repeatæ‰©å±•åˆ°32å¤´")
    print("â€¢ æ³¨æ„åŠ›è¾“å‡º: [1000, 2560]")
    print("â€¢ ç»è¿‡O_proj: [1000, 2560]")

    print("\n" + "=" * 80)


if __name__ == "__main__":
    analyze_qwen3_vl_matrix_sizes()