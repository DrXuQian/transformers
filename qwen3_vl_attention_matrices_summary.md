# Qwen3-VL 注意力矩阵参数总结

## Vision Encoder 注意力矩阵

| 矩阵 | 输入维度 | 输出维度 | 参数形状 | 参数量 | 备注 |
|------|---------|---------|----------|--------|------|
| **QKV (合并)** | 1024 | 3072 | [1024, 3072] | 3,145,728 | 包含Q、K、V三个矩阵 |
| Bias (QKV) | - | 3072 | [3072] | 3,072 | QKV的偏置项 |
| **Output Proj** | 1024 | 1024 | [1024, 1024] | 1,048,576 | 无偏置 |
| **每层总计** | - | - | - | 4,197,376 | - |
| **24层总计** | - | - | - | 100,737,024 | ~100M参数 |

拆分后的QKV：
- Q: [1024, 1024]
- K: [1024, 1024]
- V: [1024, 1024]

## LLM Decoder 注意力矩阵

| 矩阵 | 输入维度 | 输出维度 | 参数形状 | 参数量 | 备注 |
|------|---------|---------|----------|--------|------|
| **Q Proj** | 2560 | 2560 | [2560, 2560] | 6,553,600 | 32个注意力头 |
| **K Proj** | 2560 | 640 | [2560, 640] | 1,638,400 | 8个KV头 (GQA 4:1) |
| **V Proj** | 2560 | 640 | [2560, 640] | 1,638,400 | 8个KV头 (GQA 4:1) |
| **Output Proj** | 2560 | 2560 | [2560, 2560] | 6,553,600 | 无偏置 |
| **每层总计** | - | - | - | 16,384,000 | - |
| **36层总计** | - | - | - | 589,824,000 | ~590M参数 |

## 关键对比

| 特性 | Vision Encoder | LLM Decoder | 差异倍数 |
|-----|---------------|-------------|---------|
| **QKV形式** | 合并的QKV | 分离的Q、K、V | - |
| **GQA** | 无 (16:16:16) | 4:1 (32:8:8) | - |
| **Bias** | 有 (QKV) | 无 | - |
| **每层参数量** | 4.2M | 16.4M | 3.9× |
| **总层数** | 24 | 36 | 1.5× |
| **注意力总参数** | 100.7M | 589.8M | 5.9× |

## 计算效率影响

### Vision Encoder
- **内存访问**: 单次读取QKV矩阵，减少内存访问次数
- **计算密度**: 合并矩阵提高矩阵乘法效率
- **并行度**: 16个头完全并行

### LLM Decoder
- **GQA优化**: K/V参数减少75%，显著降低KV Cache内存
- **推理加速**: KV Cache小4倍，长序列推理更高效
- **灵活性**: Q可以有更多头数，保持表达能力

## 实际推理时的内存占用

假设序列长度 = 1000，批次大小 = 1，使用FP16：

### Vision Encoder (每层)
- QKV激活: 1000 × 3072 × 2 bytes = 6.1 MB
- 注意力分数: 1000 × 1000 × 16 heads × 2 bytes = 32 MB
- 输出: 1000 × 1024 × 2 bytes = 2.0 MB

### LLM Decoder (每层)
- Q激活: 1000 × 2560 × 2 bytes = 5.1 MB
- K激活: 1000 × 640 × 2 bytes = 1.3 MB
- V激活: 1000 × 640 × 2 bytes = 1.3 MB
- KV Cache (累积): 2000 × 640 × 2 bytes = 2.6 MB/层
- 输出: 1000 × 2560 × 2 bytes = 5.1 MB

**GQA的内存优势**: KV Cache减少75%，这在长序列生成时尤其重要。