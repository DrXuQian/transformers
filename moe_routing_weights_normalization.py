"""
MoEä¸­çš„å½’ä¸€åŒ–æƒé‡è¯¦è§£
åŸºäºQwen3-VL-MoEçš„å®é™…ä»£ç 
"""

import torch
import torch.nn.functional as F

def explain_moe_routing_normalization():
    """
    è§£é‡ŠMoEè·¯ç”±æƒé‡å½’ä¸€åŒ–çš„è¿‡ç¨‹
    """

    print("=" * 80)
    print("MoEä¸­çš„å½’ä¸€åŒ–æƒé‡ï¼ˆNormalized Routing Weightsï¼‰è¯¦è§£")
    print("=" * 80)

    print("\nğŸ“ 1. å®Œæ•´çš„è·¯ç”±è¿‡ç¨‹")
    print("-" * 40)
    print("""
    åŸºäºQwen3-VL-MoEçš„ä»£ç ï¼ˆmodeling_qwen3_vl_moe.py:145-148ï¼‰:

    # Step 1: è®¡ç®—è·¯ç”±logits
    router_logits = self.gate(hidden_states)  # [batch*seq_len, num_experts]

    # Step 2: åº”ç”¨softmaxå¾—åˆ°æ¦‚ç‡åˆ†å¸ƒ
    routing_weights = F.softmax(router_logits, dim=-1)  # [batch*seq_len, num_experts]

    # Step 3: é€‰æ‹©top-kä¸“å®¶
    routing_weights, router_indices = torch.topk(routing_weights, self.top_k, dim=-1)
    # routing_weights: [batch*seq_len, top_k] - top-kä¸ªä¸“å®¶çš„åˆ†æ•°
    # router_indices: [batch*seq_len, top_k] - top-kä¸ªä¸“å®¶çš„ç´¢å¼•

    # Step 4: å½’ä¸€åŒ–top-kçš„æƒé‡ï¼ˆå…³é”®æ­¥éª¤ï¼ï¼‰
    routing_weights = routing_weights / routing_weights.sum(dim=-1, keepdim=True)
    """)

    print("\nğŸ” 2. ä¸ºä»€ä¹ˆéœ€è¦å½’ä¸€åŒ–ï¼Ÿ")
    print("-" * 40)
    print("""
    åŸå› åˆ†æï¼š

    1. Softmaxåçš„å®Œæ•´åˆ†å¸ƒï¼š
       - æ‰€æœ‰128ä¸ªä¸“å®¶çš„æ¦‚ç‡å’Œ = 1.0
       - ä¾‹å¦‚ï¼š[0.15, 0.12, 0.08, 0.07, 0.06, ...] æ€»å’Œ = 1.0

    2. é€‰æ‹©top-8åï¼š
       - åªä¿ç•™8ä¸ªæœ€é«˜åˆ†æ•°ï¼š[0.15, 0.12, 0.08, 0.07, 0.06, 0.05, 0.04, 0.03]
       - è¿™8ä¸ªåˆ†æ•°çš„å’Œ < 1.0 (ä¾‹å¦‚ï¼š0.60)
       - ä¸¢å¤±äº†å…¶ä»–120ä¸ªä¸“å®¶çš„40%æ¦‚ç‡è´¨é‡

    3. é‡æ–°å½’ä¸€åŒ–çš„å¿…è¦æ€§ï¼š
       - ç¡®ä¿é€‰ä¸­ä¸“å®¶çš„æƒé‡å’Œ = 1.0
       - ä¿æŒè¾“å‡ºçš„æ•°å€¼ç¨³å®šæ€§
       - é¿å…ä¿¡æ¯æŸå¤±
    """)

    print("\nğŸ’» 3. å…·ä½“ç¤ºä¾‹")
    print("-" * 40)

    # æ¨¡æ‹Ÿä¸€ä¸ªä¾‹å­
    torch.manual_seed(42)
    batch_seq_len = 2  # 2ä¸ªtoken
    num_experts = 128  # 128ä¸ªä¸“å®¶
    top_k = 8  # é€‰æ‹©top-8

    # Step 1: æ¨¡æ‹Ÿrouter logits
    router_logits = torch.randn(batch_seq_len, num_experts)
    print(f"Router logits shape: {router_logits.shape}")

    # Step 2: Softmax
    routing_weights_full = F.softmax(router_logits, dim=-1)
    print(f"\nSoftmaxåï¼ˆå…¨éƒ¨ä¸“å®¶ï¼‰:")
    print(f"â€¢ Shape: {routing_weights_full.shape}")
    print(f"â€¢ æ¯ä¸ªtokençš„æ¦‚ç‡å’Œ: {routing_weights_full.sum(dim=-1).tolist()}")

    # Step 3: Top-k selection
    routing_weights_topk, router_indices = torch.topk(routing_weights_full, top_k, dim=-1)
    print(f"\nTop-{top_k}é€‰æ‹©åï¼ˆå½’ä¸€åŒ–å‰ï¼‰:")
    print(f"â€¢ Shape: {routing_weights_topk.shape}")
    print(f"â€¢ Top-{top_k}æƒé‡å’Œ: {routing_weights_topk.sum(dim=-1).tolist()}")
    print(f"â€¢ ç¬¬ä¸€ä¸ªtokençš„top-{top_k}æƒé‡: {routing_weights_topk[0].tolist()[:5]}... (æ˜¾ç¤ºå‰5ä¸ª)")

    # Step 4: Normalization
    routing_weights_normalized = routing_weights_topk / routing_weights_topk.sum(dim=-1, keepdim=True)
    print(f"\nå½’ä¸€åŒ–å:")
    print(f"â€¢ Shape: {routing_weights_normalized.shape}")
    print(f"â€¢ å½’ä¸€åŒ–åæƒé‡å’Œ: {routing_weights_normalized.sum(dim=-1).tolist()}")
    print(f"â€¢ ç¬¬ä¸€ä¸ªtokençš„å½’ä¸€åŒ–æƒé‡: {routing_weights_normalized[0].tolist()[:5]}... (æ˜¾ç¤ºå‰5ä¸ª)")

    # å¯¹æ¯”å½’ä¸€åŒ–å‰å
    print(f"\nå½’ä¸€åŒ–æ•ˆæœå¯¹æ¯”ï¼ˆç¬¬ä¸€ä¸ªtokençš„å‰3ä¸ªä¸“å®¶ï¼‰:")
    for i in range(3):
        before = routing_weights_topk[0, i].item()
        after = routing_weights_normalized[0, i].item()
        scale = after / before
        print(f"â€¢ ä¸“å®¶{i}: {before:.4f} â†’ {after:.4f} (æ”¾å¤§{scale:.2f}å€)")

    print("\n" + "=" * 80)
    print("ğŸ“Š 4. æ•°å­¦å…¬å¼")
    print("-" * 40)
    print("""
    è®¾ï¼š
    â€¢ S = softmax(router_logits) âˆˆ R^{NÃ—E}  (N=tokens, E=experts)
    â€¢ W_topk, I_topk = topk(S, k)  (é€‰æ‹©top-k)
    â€¢ W_topk âˆˆ R^{NÃ—k}: top-kä¸“å®¶çš„åŸå§‹softmaxåˆ†æ•°
    â€¢ I_topk âˆˆ R^{NÃ—k}: top-kä¸“å®¶çš„ç´¢å¼•

    å½’ä¸€åŒ–å…¬å¼ï¼š
    W_normalized[i,j] = W_topk[i,j] / Î£(W_topk[i,:])

    ç¡®ä¿ï¼š
    Î£(W_normalized[i,:]) = 1.0  âˆ€i âˆˆ [1,N]
    """)

    print("\nğŸ¯ 5. å®é™…å½±å“")
    print("-" * 40)
    print("""
    å½’ä¸€åŒ–æƒé‡çš„ä½œç”¨ï¼š

    1. **æ•°å€¼ç¨³å®šæ€§**ï¼š
       - ç¡®ä¿åŠ æƒæ±‚å’Œæ—¶è¾“å‡ºå¹…åº¦æ­£ç¡®
       - é¿å…è¾“å‡ºå€¼è¿‡å°ï¼ˆæœªå½’ä¸€åŒ–æ—¶å¯èƒ½åªæœ‰0.6å€ï¼‰

    2. **æ¢¯åº¦æµ**ï¼š
       - ä¿æŒæ¢¯åº¦çš„åˆç†èŒƒå›´
       - é¿å…æ¢¯åº¦æ¶ˆå¤±

    3. **ä¸“å®¶è´Ÿè½½å‡è¡¡**ï¼š
       - å½’ä¸€åŒ–åçš„æƒé‡æ›´å‡†ç¡®åæ˜ ç›¸å¯¹é‡è¦æ€§
       - æœ‰åŠ©äºload balancing lossçš„è®¡ç®—

    4. **è¾“å‡ºä¸€è‡´æ€§**ï¼š
       - æ— è®ºé€‰æ‹©å¤šå°‘ä¸“å®¶ï¼Œè¾“å‡ºscaleä¿æŒä¸€è‡´
       - output = Î£(W_normalized[i] * Expert_i(x))
    """)

    print("\nğŸ’¡ 6. Qwen3-VL-MoEçš„å…·ä½“å®ç°")
    print("-" * 40)
    print("""
    åœ¨Qwen3-VL-30B-A3B-Instructä¸­ï¼š
    â€¢ æ€»ä¸“å®¶æ•°ï¼š128
    â€¢ æ¿€æ´»ä¸“å®¶æ•°ï¼š8
    â€¢ å½’ä¸€åŒ–ç¡®ä¿è¿™8ä¸ªä¸“å®¶çš„æƒé‡å’Œ = 1.0

    ä»£ç ä½ç½®ï¼šmodeling_qwen3_vl_moe.py
    ç¬¬148è¡Œï¼šrouting_weights = routing_weights / routing_weights.sum(dim=-1, keepdim=True)

    è¿™è¡Œä»£ç å°±æ˜¯å¯¹top-8ä¸“å®¶çš„æƒé‡è¿›è¡Œé‡æ–°å½’ä¸€åŒ–ï¼
    """)

    print("=" * 80)


def compare_with_without_normalization():
    """
    å¯¹æ¯”æœ‰æ— å½’ä¸€åŒ–çš„å·®å¼‚
    """
    print("\n\nå¯¹æ¯”å®éªŒï¼šæœ‰æ— å½’ä¸€åŒ–çš„å·®å¼‚")
    print("=" * 80)

    torch.manual_seed(42)

    # æ¨¡æ‹Ÿä¸“å®¶è¾“å‡º
    num_tokens = 1
    hidden_dim = 256
    num_experts = 128
    top_k = 8

    # Router logitså’Œé€‰æ‹©
    router_logits = torch.randn(num_tokens, num_experts)
    routing_weights = F.softmax(router_logits, dim=-1)
    topk_weights, topk_indices = torch.topk(routing_weights, top_k, dim=-1)

    # æ¨¡æ‹Ÿæ¯ä¸ªä¸“å®¶çš„è¾“å‡º
    x = torch.randn(num_tokens, hidden_dim)
    expert_outputs = torch.randn(top_k, num_tokens, hidden_dim) * 2  # ä¸“å®¶è¾“å‡º

    print("å®éªŒè®¾ç½®ï¼š")
    print(f"â€¢ Top-{top_k}æƒé‡å’Œï¼ˆå½’ä¸€åŒ–å‰ï¼‰: {topk_weights.sum().item():.4f}")
    print(f"â€¢ è¾“å…¥xçš„L2èŒƒæ•°: {x.norm().item():.4f}")

    # æ— å½’ä¸€åŒ–çš„è¾“å‡º
    output_no_norm = torch.zeros_like(x)
    for i in range(top_k):
        output_no_norm += topk_weights[0, i] * expert_outputs[i, 0]

    # æœ‰å½’ä¸€åŒ–çš„è¾“å‡º
    normalized_weights = topk_weights / topk_weights.sum(dim=-1, keepdim=True)
    output_with_norm = torch.zeros_like(x)
    for i in range(top_k):
        output_with_norm += normalized_weights[0, i] * expert_outputs[i, 0]

    print(f"\nè¾“å‡ºå¯¹æ¯”ï¼š")
    print(f"â€¢ æ— å½’ä¸€åŒ–è¾“å‡ºçš„L2èŒƒæ•°: {output_no_norm.norm().item():.4f}")
    print(f"â€¢ æœ‰å½’ä¸€åŒ–è¾“å‡ºçš„L2èŒƒæ•°: {output_with_norm.norm().item():.4f}")
    print(f"â€¢ èŒƒæ•°æ¯”ä¾‹: {output_with_norm.norm().item() / output_no_norm.norm().item():.4f}")

    print(f"\nç»“è®ºï¼š")
    print(f"å½’ä¸€åŒ–ä½¿è¾“å‡ºå¹…åº¦å¢å¤§çº¦ {1/topk_weights.sum().item():.2f} å€")
    print("è¿™ä¿è¯äº†æ¨¡å‹å„å±‚çš„æ¿€æ´»å€¼ä¿æŒåœ¨åˆç†èŒƒå›´å†…")

    print("=" * 80)


if __name__ == "__main__":
    explain_moe_routing_normalization()
    compare_with_without_normalization()