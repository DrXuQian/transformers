"""
DeepStack Visionç‰¹å¾æå–æµç¨‹è¯¦è§£
å±•ç¤ºVision Transformerå¦‚ä½•è¾“å‡ºå¤šå±‚ç‰¹å¾
"""

import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import matplotlib.patches as patches

class Qwen3VLVisionEncoder(nn.Module):
    """
    Qwen3-VLçš„Vision Encoder
    å±•ç¤ºå¦‚ä½•ä»ä¸åŒå±‚æå–ç‰¹å¾
    """
    def __init__(self, config):
        super().__init__()

        # Vision Transformeræœ‰24å±‚
        self.depth = 24
        self.hidden_size = 1024

        # Patch Embedding
        self.patch_embed = nn.Conv3d(
            in_channels=3,
            out_channels=1024,
            kernel_size=(2, 16, 16),  # (temporal, height, width)
            stride=(2, 16, 16)
        )

        # 24ä¸ªVision Transformer Blocks
        self.blocks = nn.ModuleList([
            VisionTransformerBlock(hidden_size=1024)
            for _ in range(24)
        ])

        # DeepStacké…ç½®ï¼šåœ¨å“ªäº›å±‚è¾“å‡ºç‰¹å¾
        self.deepstack_visual_indexes = [5, 11, 17]  # ç¬¬5ã€11ã€17å±‚

        # ä¸ºæ¯ä¸ªDeepStackå±‚é…ç½®ç‹¬ç«‹çš„Patch Merger
        # å°†1024ç»´çš„visionç‰¹å¾è½¬æ¢ä¸º2560ç»´çš„LLMç‰¹å¾
        self.deepstack_mergers = nn.ModuleDict({
            '5': PatchMerger(1024, 2560),   # Layer 5 merger
            '11': PatchMerger(1024, 2560),  # Layer 11 merger
            '17': PatchMerger(1024, 2560),  # Layer 17 merger
        })

        # æœ€ç»ˆè¾“å‡ºçš„Patch Merger
        self.final_merger = PatchMerger(1024, 2560)

    def forward(self, pixel_values):
        """
        è¾“å…¥ï¼šå›¾åƒåƒç´ å€¼
        è¾“å‡ºï¼š
            1. final_features: æœ€ç»ˆçš„è§†è§‰ç‰¹å¾ï¼ˆLayer 24çš„è¾“å‡ºï¼‰
            2. deepstack_features: ä¸­é—´å±‚çš„è§†è§‰ç‰¹å¾å­—å…¸
        """

        # Step 1: Patch Embedding
        # [B, C, T, H, W] -> [B*num_patches, hidden_size]
        hidden_states = self.patch_embed(pixel_values)
        hidden_states = hidden_states.flatten(2).transpose(1, 2)

        print(f"Initial shape after patch embedding: {hidden_states.shape}")
        # ä¾‹å¦‚: [batch_size, num_patches, 1024]

        # ç”¨äºå­˜å‚¨DeepStackç‰¹å¾
        deepstack_features = {}

        # Step 2: é€å±‚å¤„ç†ï¼Œå¹¶åœ¨ç‰¹å®šå±‚æå–ç‰¹å¾
        for layer_idx, block in enumerate(self.blocks):
            # é€šè¿‡å½“å‰Vision Transformer Block
            hidden_states = block(hidden_states)

            print(f"Layer {layer_idx}: shape = {hidden_states.shape}")

            # æ£€æŸ¥æ˜¯å¦æ˜¯DeepStackå±‚
            if layer_idx in self.deepstack_visual_indexes:
                # æå–å½“å‰å±‚çš„è¾“å‡º
                print(f"  â†’ DeepStack extraction at layer {layer_idx}")

                # ä½¿ç”¨å¯¹åº”çš„mergerè½¬æ¢ç»´åº¦
                merger = self.deepstack_mergers[str(layer_idx)]
                deepstack_feature = merger(hidden_states)

                # ä¿å­˜åˆ°å­—å…¸ä¸­
                deepstack_features[f'layer_{layer_idx}'] = deepstack_feature

                print(f"  â†’ Extracted feature shape: {deepstack_feature.shape}")
                # ä» [batch, patches, 1024] -> [batch, patches, 2560]

        # Step 3: æœ€ç»ˆè¾“å‡ºå¤„ç†
        final_features = self.final_merger(hidden_states)
        print(f"Final features shape: {final_features.shape}")

        return final_features, deepstack_features


class VisionTransformerBlock(nn.Module):
    """
    å•ä¸ªVision Transformer Block
    """
    def __init__(self, hidden_size):
        super().__init__()
        self.norm1 = nn.LayerNorm(hidden_size)
        self.attention = nn.MultiheadAttention(
            embed_dim=hidden_size,
            num_heads=16,
            batch_first=True
        )
        self.norm2 = nn.LayerNorm(hidden_size)
        self.mlp = nn.Sequential(
            nn.Linear(hidden_size, hidden_size * 4),
            nn.GELU(),
            nn.Linear(hidden_size * 4, hidden_size)
        )

    def forward(self, x):
        # Self-Attention with residual
        residual = x
        x = self.norm1(x)
        x, _ = self.attention(x, x, x)
        x = residual + x

        # MLP with residual
        residual = x
        x = self.norm2(x)
        x = self.mlp(x)
        x = residual + x

        return x


class PatchMerger(nn.Module):
    """
    Patch Merger: è½¬æ¢visionç‰¹å¾åˆ°LLMç»´åº¦
    """
    def __init__(self, in_dim, out_dim):
        super().__init__()
        self.norm = nn.LayerNorm(in_dim)
        self.proj = nn.Linear(in_dim, out_dim)

    def forward(self, x):
        return self.proj(self.norm(x))


def visualize_deepstack_flow():
    """
    å¯è§†åŒ–DeepStackçš„ç‰¹å¾æå–æµç¨‹
    """
    fig, ax = plt.subplots(1, 1, figsize=(14, 10))

    # è®¾ç½®åæ ‡è½´
    ax.set_xlim(0, 14)
    ax.set_ylim(0, 26)
    ax.axis('off')

    # æ ‡é¢˜
    ax.text(7, 25, 'DeepStack Vision Feature Extraction Flow',
            fontsize=16, fontweight='bold', ha='center')

    # è¾“å…¥å›¾åƒ
    img_rect = patches.Rectangle((1, 22), 2, 2,
                                 linewidth=2, edgecolor='green',
                                 facecolor='lightgreen')
    ax.add_patch(img_rect)
    ax.text(2, 21.5, 'Input Image', ha='center', fontsize=10)

    # Patch Embedding
    pe_rect = patches.Rectangle((0.5, 19), 3, 1.5,
                                linewidth=2, edgecolor='blue',
                                facecolor='lightblue')
    ax.add_patch(pe_rect)
    ax.text(2, 19.75, 'Patch Embed', ha='center', fontsize=10)
    ax.text(2, 19.25, '16Ã—16 patches', ha='center', fontsize=8)

    # Vision Transformer Blocks
    layer_y_positions = []
    for i in range(24):
        y_pos = 18 - i * 0.7
        layer_y_positions.append(y_pos)

        # åˆ¤æ–­æ˜¯å¦æ˜¯DeepStackå±‚
        if i in [5, 11, 17]:
            color = 'red'
            facecolor = 'lightcoral'
            linewidth = 3
        else:
            color = 'gray'
            facecolor = 'lightgray'
            linewidth = 1

        # Vision BlockçŸ©å½¢
        block_rect = patches.Rectangle((0.5, y_pos - 0.3), 3, 0.6,
                                      linewidth=linewidth,
                                      edgecolor=color,
                                      facecolor=facecolor)
        ax.add_patch(block_rect)

        # å±‚ç¼–å·
        ax.text(0.2, y_pos, f'L{i}', ha='center', fontsize=8)
        ax.text(2, y_pos, f'ViT Block {i}', ha='center', fontsize=9)

        # å¦‚æœæ˜¯DeepStackå±‚ï¼Œç”»å‡ºæå–ç®­å¤´
        if i in [5, 11, 17]:
            # ç®­å¤´æŒ‡å‘å³ä¾§
            ax.arrow(3.5, y_pos, 2, 0,
                    head_width=0.2, head_length=0.1,
                    fc='red', ec='red')

            # Patch Merger
            merger_rect = patches.Rectangle((5.8, y_pos - 0.3), 2.5, 0.6,
                                          linewidth=2,
                                          edgecolor='purple',
                                          facecolor='plum')
            ax.add_patch(merger_rect)
            ax.text(7.05, y_pos, f'Merger {i}', ha='center', fontsize=9)

            # ç®­å¤´æŒ‡å‘LLM
            ax.arrow(8.3, y_pos, 2, 0,
                    head_width=0.2, head_length=0.1,
                    fc='purple', ec='purple')

            # LLMå±‚æ ‡æ³¨
            llm_rect = patches.Rectangle((10.5, y_pos - 0.3), 2.5, 0.6,
                                        linewidth=2,
                                        edgecolor='orange',
                                        facecolor='lightyellow')
            ax.add_patch(llm_rect)

            if i == 5:
                ax.text(11.75, y_pos, 'LLM L0-3', ha='center', fontsize=9)
                ax.text(11.75, y_pos - 0.15, '(ä½çº§ç‰¹å¾)', ha='center', fontsize=7)
            elif i == 11:
                ax.text(11.75, y_pos, 'LLM L4-7', ha='center', fontsize=9)
                ax.text(11.75, y_pos - 0.15, '(ä¸­çº§ç‰¹å¾)', ha='center', fontsize=7)
            elif i == 17:
                ax.text(11.75, y_pos, 'LLM L8-11', ha='center', fontsize=9)
                ax.text(11.75, y_pos - 0.15, '(é«˜çº§ç‰¹å¾)', ha='center', fontsize=7)

    # æœ€ç»ˆè¾“å‡º
    final_y = layer_y_positions[-1] - 1.5
    final_rect = patches.Rectangle((0.5, final_y - 0.3), 3, 0.6,
                                  linewidth=2, edgecolor='green',
                                  facecolor='lightgreen')
    ax.add_patch(final_rect)
    ax.text(2, final_y, 'Final Merger', ha='center', fontsize=10)

    # ç®­å¤´åˆ°LLMè¾“å…¥
    ax.arrow(3.5, final_y, 2, 0,
            head_width=0.2, head_length=0.1,
            fc='green', ec='green')

    input_rect = patches.Rectangle((5.8, final_y - 0.3), 2.5, 0.6,
                                  linewidth=2, edgecolor='orange',
                                  facecolor='lightyellow')
    ax.add_patch(input_rect)
    ax.text(7.05, final_y, 'LLM Input', ha='center', fontsize=10)

    # æ·»åŠ å›¾ä¾‹
    legend_elements = [
        patches.Patch(color='lightgray', label='Regular ViT Block'),
        patches.Patch(color='lightcoral', label='DeepStack Block'),
        patches.Patch(color='plum', label='Patch Merger'),
        patches.Patch(color='lightyellow', label='To LLM')
    ]
    ax.legend(handles=legend_elements, loc='upper right')

    # æ·»åŠ è¯´æ˜æ–‡å­—
    ax.text(7, 0.5, 'All features come from the SAME Vision Transformer,',
            ha='center', fontsize=11, style='italic')
    ax.text(7, 0, 'just extracted at different depths (layers 5, 11, 17)',
            ha='center', fontsize=11, style='italic', color='red')

    plt.title('Qwen3-VL DeepStack: Multi-layer Vision Feature Extraction',
             fontsize=14, fontweight='bold', pad=20)
    plt.tight_layout()
    plt.savefig('/home/qianxu/transformers/deepstack_flow.png', dpi=150, bbox_inches='tight')
    plt.show()


def demonstrate_feature_extraction():
    """
    æ¼”ç¤ºå®é™…çš„ç‰¹å¾æå–è¿‡ç¨‹
    """
    print("=" * 70)
    print("DeepStack Visionç‰¹å¾æå–æ¼”ç¤º")
    print("=" * 70)

    # åˆ›å»ºæ¨¡æ‹Ÿé…ç½®
    class Config:
        pass

    config = Config()

    # åˆ›å»ºVision Encoder
    vision_encoder = Qwen3VLVisionEncoder(config)

    # æ¨¡æ‹Ÿè¾“å…¥
    batch_size = 2
    pixel_values = torch.randn(batch_size, 3, 2, 224, 224)  # [B, C, T, H, W]

    print(f"\nè¾“å…¥å›¾åƒshape: {pixel_values.shape}")
    print("  - Batch size: 2")
    print("  - Channels: 3 (RGB)")
    print("  - Temporal: 2 frames")
    print("  - Spatial: 224Ã—224")

    print("\n" + "-" * 70)
    print("å¤„ç†è¿‡ç¨‹ï¼š")
    print("-" * 70)

    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        final_features, deepstack_features = vision_encoder(pixel_values)

    print("\n" + "-" * 70)
    print("è¾“å‡ºç»“æœï¼š")
    print("-" * 70)

    print(f"\n1. æœ€ç»ˆç‰¹å¾ (Layer 24è¾“å‡º):")
    print(f"   Shape: {final_features.shape}")
    print(f"   ç”¨é€”: ä½œä¸ºLLMçš„ä¸»è¦è§†è§‰è¾“å…¥")

    print(f"\n2. DeepStackä¸­é—´ç‰¹å¾:")
    for key, features in deepstack_features.items():
        print(f"   {key}:")
        print(f"     Shape: {features.shape}")
        print(f"     ç»´åº¦: 1024 -> 2560 (è½¬æ¢åˆ°LLMç»´åº¦)")

    print("\n" + "=" * 70)


def explain_implementation():
    """
    è§£é‡Šå®é™…å®ç°ç»†èŠ‚
    """
    print("\n" + "=" * 70)
    print("ğŸ’¡ å…³é”®å®ç°ç»†èŠ‚")
    print("=" * 70)

    details = {
        "1. å•ä¸€Vision Transformer": [
            "åªæœ‰ä¸€ä¸ªVision Encoderï¼Œä¸æ˜¯å¤šä¸ª",
            "è¾“å…¥å›¾åƒåªå¤„ç†ä¸€æ¬¡",
            "é€šè¿‡24ä¸ªViT Blocké¡ºåºå¤„ç†"
        ],

        "2. ä¸­é—´å±‚ç‰¹å¾æå–": [
            "åœ¨forwardè¿‡ç¨‹ä¸­ï¼Œä¿å­˜ç‰¹å®šå±‚çš„è¾“å‡º",
            "Layer 5: hidden_statesåœ¨ç¬¬5å±‚åçš„çŠ¶æ€",
            "Layer 11: hidden_statesåœ¨ç¬¬11å±‚åçš„çŠ¶æ€",
            "Layer 17: hidden_statesåœ¨ç¬¬17å±‚åçš„çŠ¶æ€",
            "Layer 24: æœ€ç»ˆçš„hidden_states"
        ],

        "3. Patch Mergerçš„ä½œç”¨": [
            "Visionç‰¹å¾ç»´åº¦: 1024",
            "LLMéœ€è¦ç»´åº¦: 2560",
            "æ¯ä¸ªDeepStackå±‚æœ‰ç‹¬ç«‹çš„Merger",
            "Merger = LayerNorm + LinearæŠ•å½±"
        ],

        "4. ä¸ºä»€ä¹ˆé€‰æ‹©5ã€11ã€17å±‚": [
            "Layer 5 (æµ…å±‚): æ•è·ä½çº§è§†è§‰ç‰¹å¾",
            "Layer 11 (ä¸­å±‚): æ•è·ä¸­çº§è¯­ä¹‰ç‰¹å¾",
            "Layer 17 (æ·±å±‚): æ•è·é«˜çº§æŠ½è±¡ç‰¹å¾",
            "å‡åŒ€åˆ†å¸ƒåœ¨24å±‚ä¸­ï¼Œè¦†ç›–ä¸åŒæŠ½è±¡å±‚æ¬¡"
        ],

        "5. å†…å­˜å’Œè®¡ç®—å¼€é”€": [
            "éœ€è¦å­˜å‚¨4ä»½è§†è§‰ç‰¹å¾(final + 3ä¸ªä¸­é—´å±‚)",
            "æ¯ä¸ªMergerå¢åŠ çº¦2.6Må‚æ•°(1024Ã—2560)",
            "æ€»å…±å¢åŠ çº¦10Må‚æ•°ç”¨äºDeepStack",
            "å‰å‘ä¼ æ’­æ—¶éœ€è¦é¢å¤–çš„ç‰¹å¾å¤åˆ¶å’Œè½¬æ¢"
        ]
    }

    for title, items in details.items():
        print(f"\n{title}:")
        for item in items:
            print(f"  â€¢ {item}")

    print("\n" + "=" * 70)


def show_actual_code():
    """
    å±•ç¤ºå®é™…ä»£ç ç‰‡æ®µ
    """
    print("\n" + "=" * 70)
    print("ğŸ“ Qwen3-VL å®é™…ä»£ç ")
    print("=" * 70)

    actual_code = '''
# modeling_qwen3_vl.py ä¸­çš„å®é™…å®ç°

class Qwen3VLVisionTransformerPretrainedModel(nn.Module):
    def __init__(self, config):
        super().__init__()
        self.blocks = nn.ModuleList([
            Qwen3VLVisionBlock(config) for _ in range(config.depth)
        ])

        # DeepStack mergers
        self.deepstack_mergers = nn.ModuleDict()
        for idx in config.deepstack_visual_indexes:
            self.deepstack_mergers[str(idx)] = Qwen3VLVisionPatchMerger(
                config, use_postshuffle_norm=True
            )

    def forward(self, hidden_states, cu_seqlens, rotary_pos_emb):
        # æ”¶é›†DeepStack embeddings
        deepstack_embeds = []

        for idx, blk in enumerate(self.blocks):
            # é€šè¿‡Vision Block
            hidden_states = blk(
                hidden_states=hidden_states,
                cu_seqlens=cu_seqlens,
                rotary_pos_emb=rotary_pos_emb
            )

            # å¦‚æœæ˜¯DeepStackå±‚ï¼Œæå–ç‰¹å¾
            if idx in self.config.deepstack_visual_indexes:
                merger = self.deepstack_mergers[str(idx)]
                deepstack_embeds.append(merger(hidden_states))

        # æœ€ç»ˆè¾“å‡º
        hidden_states = self.merger(hidden_states)

        return hidden_states, deepstack_embeds
    '''

    print(actual_code)
    print("\n" + "=" * 70)


if __name__ == "__main__":
    # 1. æ¼”ç¤ºç‰¹å¾æå–è¿‡ç¨‹
    demonstrate_feature_extraction()

    # 2. å¯è§†åŒ–æµç¨‹å›¾
    print("\nç”ŸæˆDeepStackæµç¨‹å›¾...")
    visualize_deepstack_flow()
    print("æµç¨‹å›¾å·²ä¿å­˜åˆ°: deepstack_flow.png")

    # 3. è§£é‡Šå®ç°ç»†èŠ‚
    explain_implementation()

    # 4. å±•ç¤ºå®é™…ä»£ç 
    show_actual_code()

    print("\n" + "=" * 70)
    print("âœ… æ€»ç»“ï¼šDeepStackçš„æ‰€æœ‰è§†è§‰ç‰¹å¾éƒ½æ¥è‡ªåŒä¸€ä¸ªVision Transformerï¼Œ")
    print("   åªæ˜¯åœ¨ä¸åŒçš„å¤„ç†æ·±åº¦(å±‚)è¢«æå–å‡ºæ¥å¹¶æ³¨å…¥åˆ°LLMä¸­ã€‚")
    print("=" * 70)